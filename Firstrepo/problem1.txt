


sqoop import --connect "jdbc:mysql://quickstart.cloudera:3306//retail_db"
--username retail_dba
--password cloudera
--table orders
--target-dir /user/cloudera/problem1/orders
--compress
--compression-codec 'org.apcahe.hadoop.io.compress.SnappyCodec'
--as-avrodatafile

similarly, for order_items


import org.apache.spark.sql.functions._
import com.databricks.spark.avro._


var order_itemsdf = sqlContext.read.avro("/user/cloudera/problem1/order_item")

var ordersdf = sqlContext.read.avro("/user/cloudera/problem1/orders")

var joindf = ordersdf.join(order_itemsdf,ordersdf("order_id") === order_itemsdf("order_item_order_id"))

joindf.groupBy(to_date(from_unixtime(col("order_date")/1000)).alias("order_new_date"),col("order_status")).agg(round(sum(col("order_item_subtotal")),2).alias("order_amount"),countDistinct(col("order_id")).alias("order_count")).orderBy(col("order_new_date") desc,col("order_status"),col("order_amount") desc,col("order_count"))show()


var finalresultdf = joindf.groupBy(to_date(from_unixtime(col("order_date")/1000)).alias("order_new_date"),col("order_status")).agg(round(sum(col("order_item_subtotal")),2).alias("order_amount"),countDistinct(col("order_id")).alias("order_count")).orderBy(col("order_new_date") desc,col("order_status"),col("order_amount") desc,col("order_count"))

sqlContext.setConf("spark.sql.parquet.compression.codec","gzip")

finalresultdf.write.parquet("/user/cloudera/problem1/finalresult1")

create table finalresult1(order_date varchar(255),order_status varchar(255),order_amount int, order_count int);

finalresult1.map(x=> x(0)+","+x(1)+","+x(2)+","+x(3)).saveAsTextFile("/user/cloudera/problem1/finalresult1.csv")

 create table finalresult1(order_date varchar(255),order_status varchar(255),order_amount numeric, order_count int,constraint pk_order_result primary key (order_date,order_status));

sqoop export --connect "jdbc:mysql://quickstart.cloudera:3306/retail_db" --table finalresult1 --username retail_dba --password  cloudera --export-dir "/user/cloudera/problem1/finalresult1.csv" 

joindf.registerTempTable("joinorders")

var sqlresult1 = sqlContext.sql("select to_date(from_unixtime(cast(order_date/1000 as bigint))) as order_new_date,order_status,cast(sum(order_item_subtotal) as decimal(10,2)) as order_totalamount,count(distinct(order_id)) as order_count from joinorders group by to_date(from_unixtime(cast(order_date/1000 as bigint))),order_status order by order_new_date desc,order_status,order_totalamount desc,order_count")




