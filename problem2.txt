


import org.apache.spark.sql.functions._
import com.databricks.spark.avro._



sqoop import --connect "jdbc:mysql://quickstart.cloudera:3306/retail_db" --username retail_dba --password cloudera --table products --fields-terminated-by '|'

hadoop fs -mkdir problem2

hadoop fs -mv products problem2


hadoop fs -chmod 765 problem2/products/*


var product = sc.textFile("/user/cloudera/problem2/products")

var productmap = product.map(x=>{var d = x.split("|");(d(0).toInt,d(1).toInt,d(2).toString,d(3).toString,d(4).toFloat,d(5).toString)});

case class products(product_id :Int,product_category_id : Int,product_name :String,product_description : String,product_price : Float,product_image:String);

var productdf = productmap.map(x=>products(x._1,x._2,x._3,x._4,x._5,x._6)).toDF();


var finalresultdf2=productdf.filter("product_price < 100").groupBy(col("product_category_id")).agg(countDistinct(col("product_id")),max(col("product_price")),min(col("product_price")),avg(col("product_price")))

productdf.registerTempTable("products")


var sqlresult2 = sqlContext.sql("select max(product_price) as max_price,min(product_price) as min_price,cast(avg(product_price) as decimal(10,2)) as avg_price,count(distinct(product_id)) as total_order  from products where product_price<100 group by product_category_id")

sqlContext.setConf("spark.sql.avro.compression.codec","snappy")





